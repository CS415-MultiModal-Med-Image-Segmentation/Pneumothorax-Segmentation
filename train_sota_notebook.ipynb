{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü´Å State-of-the-Art Pneumothorax Segmentation\n",
        "\n",
        "**A comprehensive deep learning pipeline for medical image segmentation**\n",
        "\n",
        "### Key Features (Refined):\n",
        "- ‚úÖ **UNet++ with Attention** + ResNet34 encoder (better skip connections)\n",
        "- ‚úÖ **Max pooling mask downsampling** (preserves small pneumothorax regions!)\n",
        "- ‚úÖ **SMP's DiceLoss + BCE hybrid** (well-tested implementation)\n",
        "- ‚úÖ **256√ó256 resolution** (matches working baseline)\n",
        "- ‚úÖ **Grayscale normalization** (0.5, 0.5, 0.5) for medical images\n",
        "- ‚≠ê **Kaggle winner tricks**: Class rebalancing, optimal threshold, TTA\n",
        "- ‚úÖ **Early stopping** with patience monitoring\n",
        "- ‚úÖ **Mixed precision training** for speed\n",
        "\n",
        "**Target: Dice Coefficient > 0.85**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Setup & Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies if needed (uncomment if required)\n",
        "# !pip install segmentation-models-pytorch albumentations opencv-python-headless\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.9.0+cu128\n",
            "CUDA available: True\n",
            "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
            "VRAM: 8.2 GB\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Fix HuggingFace progress bar errors in notebooks\n",
        "os.environ['HF_HUB_DISABLE_PROGRESS_BARS'] = '1'\n",
        "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Tuple, Optional, Dict, List\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Configuration ‚öôÔ∏è\n",
        "\n",
        "**Adjust these settings based on your GPU**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Configuration:\n",
            "   Device: cuda\n",
            "   Encoder: resnet34\n",
            "   Patch Size: 256\n",
            "   Batch Size: 16 (effective: 16)\n",
            "   Mode: Single Split (20% val)\n",
            "   Epochs: 30\n",
            "   Learning Rate: 8e-05\n"
          ]
        }
      ],
      "source": [
        "class Config:\n",
        "    \"\"\"Training configuration - adjust for your hardware.\"\"\"\n",
        "    \n",
        "    # === DATA PATHS ===\n",
        "    DATA_PATH = \"siim-acr-pneumothorax\"\n",
        "    # DATA_PATH = \"/kaggle/input/kkkkkkkkkkkkkkkkkkk/\"\n",
        "    TRAIN_CSV = \"stage_1_train_images.csv\"\n",
        "    TEST_CSV = \"stage_1_test_images.csv\"\n",
        "    IMAGES_DIR = \"png_images\"\n",
        "    MASKS_DIR = \"png_masks\"\n",
        "    OUTPUT_DIR = \"sota_output\"\n",
        "    \n",
        "    # === MODEL SETTINGS ===\n",
        "    ENCODER = \"resnet34\"             # CHANGED: Simpler, proven for medical imaging\n",
        "    ENCODER_WEIGHTS = \"imagenet\"\n",
        "    ATTENTION_TYPE = \"scse\"          # Spatial + Channel attention\n",
        "    \n",
        "    # === IMAGE SETTINGS ===\n",
        "    PATCH_SIZE = 256                 # CHANGED: Match original working notebook (256x256), 512 for t4\n",
        "    USE_PATCHES = False               # DISABLED: Random crops can miss pneumothorax!\n",
        "    \n",
        "    # === TRAINING MODE ===\n",
        "    # üîÑ SET THIS TO CHOOSE TRAINING MODE:\n",
        "    USE_KFOLD = False                 # False = Single Split (faster), True = K-Fold CV (robust)\n",
        "    N_FOLDS = 5                       # Number of folds (only if USE_KFOLD=True)\n",
        "    VAL_SPLIT = 0.2                   # Validation split (only if USE_KFOLD=False)\n",
        "    \n",
        "    # === TRAINING SETTINGS ===\n",
        "    # üîß ADJUST THESE FOR YOUR GPU:\n",
        "    BATCH_SIZE = 16                    # RTX 4060 (8GB): use 4-8, T4: use 12\n",
        "    GRADIENT_ACCUMULATION = 1         # Keep simple - no accumulation needed\n",
        "    EPOCHS = 30                       # Max epochs per fold\n",
        "    LEARNING_RATE = 8e-5              # FIXED: Reduced for stability (was 3e-4, too high!)\n",
        "    WEIGHT_DECAY = 1e-5               # Some regularization for generalization\n",
        "    \n",
        "    # === LOSS FUNCTION ===\n",
        "    # Standard: L = BCE/Focal + Œª * Dice (BCE/Focal at full weight, Dice weighted by Œª)\n",
        "    # Options: 'bce_dice' (default, stable) or 'focal_dice' (for extreme imbalance)\n",
        "    LOSS_TYPE = 'focal_dice'            # 'bce_dice' or 'focal_dice'\n",
        "    DICE_WEIGHT = 0.5                 # Œª parameter: Dice weight (typical 0.5‚Äì1.0)\n",
        "    FOCAL_ALPHA = 0.25                # Focal loss alpha (positive class weight)\n",
        "    FOCAL_GAMMA = 2.0                 # Focal loss gamma (focusing on hard examples)\n",
        "    \n",
        "    # === DROPOUT (Regularization) ===\n",
        "    # Recommended: 0.2 bottleneck, 0.1 decoder (SMP applies decoder dropout)\n",
        "    USE_DROPOUT = True                # Enable/disable dropout\n",
        "    DECODER_DROPOUT = 0.1             # Dropout in decoder blocks\n",
        "    \n",
        "    # === EARLY STOPPING ===\n",
        "    PATIENCE = 10                     # Stop if no improvement for N epochs\n",
        "    \n",
        "    # === HARDWARE ===\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    NUM_WORKERS = 2                   # Data loading workers\n",
        "    MIXED_PRECISION = True            # FP16 training (faster, less memory)\n",
        "    \n",
        "    SEED = 42\n",
        "\n",
        "config = Config()\n",
        "os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"üìã Configuration:\")\n",
        "print(f\"   Device: {config.DEVICE}\")\n",
        "print(f\"   Encoder: {config.ENCODER}\")\n",
        "print(f\"   Patch Size: {config.PATCH_SIZE}\")\n",
        "print(f\"   Batch Size: {config.BATCH_SIZE} (effective: {config.BATCH_SIZE * config.GRADIENT_ACCUMULATION})\")\n",
        "print(f\"   Mode: {'K-Fold CV (K=' + str(config.N_FOLDS) + ')' if config.USE_KFOLD else 'Single Split (' + str(int(config.VAL_SPLIT*100)) + '% val)'}\")\n",
        "print(f\"   Epochs: {config.EPOCHS}\")\n",
        "print(f\"   Learning Rate: {config.LEARNING_RATE}\")\n",
        "\n",
        "# Set seeds\n",
        "def seed_everything(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_everything(config.SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Loss Functions & Augmentation\n",
        "\n",
        "Using **Dice-BCE Hybrid Loss** for class imbalance and **Elastic Deformations** for medical imaging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Loss functions and augmentations defined\n"
          ]
        }
      ],
      "source": [
        "# Loss Functions - Using SMP's well-tested implementations\n",
        "# CHANGED: Use SMP's DiceLoss (well-tested, handles per-sample correctly)\n",
        "dice_loss = smp.losses.DiceLoss(mode='binary', from_logits=True)\n",
        "bce_loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "class DiceBCELoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Standard formulation: L = BCE + Œª * Dice\n",
        "    \n",
        "    BCE is taken at full weight (1.0), Dice is weighted by lambda.\n",
        "    This is the standard convention in medical segmentation.\n",
        "    \n",
        "    Typical Œª values: 0.5-1.0 (0.5 is common default)\n",
        "    \"\"\"\n",
        "    def __init__(self, dice_weight=0.5):\n",
        "        super().__init__()\n",
        "        self.dice_weight = dice_weight  # Œª parameter\n",
        "        self.dice_loss = smp.losses.DiceLoss(mode='binary', from_logits=True)\n",
        "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
        "    \n",
        "    def forward(self, pred, target):\n",
        "        # Standard: BCE (full) + Œª * Dice\n",
        "        return self.bce_loss(pred, target) + self.dice_weight * self.dice_loss(pred, target)\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Focal Loss for handling extreme class imbalance.\n",
        "    Focuses learning on hard examples (small pneumothorax regions).\n",
        "    \n",
        "    FL = -Œ±(1-p)^Œ≥ * log(p)\n",
        "    where p is the predicted probability, Œ± is weighting factor, Œ≥ is focusing parameter.\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha=0.25, gamma=2.0, from_logits=True):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.from_logits = from_logits\n",
        "    \n",
        "    def forward(self, pred, target):\n",
        "        if self.from_logits:\n",
        "            # Convert logits to probabilities\n",
        "            pred_prob = torch.sigmoid(pred)\n",
        "        else:\n",
        "            pred_prob = pred\n",
        "        \n",
        "        # BCE term (make autocast-safe by forcing float32 and disabling autocast inside)\n",
        "        with torch.cuda.amp.autocast(enabled=False):\n",
        "            bce = nn.functional.binary_cross_entropy(\n",
        "                pred_prob.float(),\n",
        "                target.float(),\n",
        "                reduction='none'\n",
        "            )\n",
        "        \n",
        "        # Focal term: (1-p)^Œ≥\n",
        "        p_t = pred_prob * target + (1 - pred_prob) * (1 - target)  # p for positive, 1-p for negative\n",
        "        focal_weight = (1 - p_t) ** self.gamma\n",
        "        \n",
        "        # Apply alpha weighting (alpha for positive class, 1-alpha for negative)\n",
        "        alpha_t = self.alpha * target + (1 - self.alpha) * (1 - target)\n",
        "        \n",
        "        # Final focal loss\n",
        "        focal_loss = alpha_t * focal_weight * bce\n",
        "        return focal_loss.mean()\n",
        "\n",
        "class DiceFocalLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Standard formulation: L = Focal + Œª * Dice\n",
        "    \n",
        "    Focal is taken at full weight (1.0), Dice is weighted by lambda.\n",
        "    Best for extreme class imbalance (very small pneumothorax regions).\n",
        "    \n",
        "    Use when:\n",
        "    - Pneumothorax regions are <1% of image\n",
        "    - Missing small lesions (high false negatives)\n",
        "    - BCE+Dice plateaus below target performance\n",
        "    \n",
        "    Typical Œª values: 0.5-1.0 (0.5 is common default)\n",
        "    \"\"\"\n",
        "    def __init__(self, dice_weight=0.5, focal_alpha=0.25, focal_gamma=2.0):\n",
        "        super().__init__()\n",
        "        self.dice_weight = dice_weight  # Œª parameter\n",
        "        self.dice_loss = smp.losses.DiceLoss(mode='binary', from_logits=True)\n",
        "        self.focal_loss = FocalLoss(alpha=focal_alpha, gamma=focal_gamma, from_logits=True)\n",
        "    \n",
        "    def forward(self, pred, target):\n",
        "        # Standard: Focal (full) + Œª * Dice\n",
        "        return self.focal_loss(pred, target) + self.dice_weight * self.dice_loss(pred, target)\n",
        "\n",
        "# Augmentation Pipelines\n",
        "def get_training_augmentation(patch_size=256):\n",
        "    \"\"\"\n",
        "    MINIMAL augmentation matching the working baseline:\n",
        "    - NO geometric transforms (baseline used none and got 0.79 Dice!)\n",
        "    - Simple (0.5, 0.5, 0.5) normalization for grayscale X-rays\n",
        "    - NO horizontal flip (chest anatomy is asymmetric)\n",
        "    \"\"\"\n",
        "    return A.Compose([\n",
        "        # CORRECT: Use grayscale-friendly normalization (not ImageNet!)\n",
        "        # ImageNet stats are for RGB natural images, not grayscale X-rays\n",
        "        A.Normalize(\n",
        "            mean=(0.5, 0.5, 0.5),  # Neutral for grayscale\n",
        "            std=(0.5, 0.5, 0.5)\n",
        "        ),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "\n",
        "def get_validation_augmentation():\n",
        "    return A.Compose([\n",
        "        # CORRECT: Use grayscale-friendly normalization (not ImageNet!)\n",
        "        A.Normalize(\n",
        "            mean=(0.5, 0.5, 0.5),  # Neutral for grayscale\n",
        "            std=(0.5, 0.5, 0.5)\n",
        "        ),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "\n",
        "# Metrics - FIXED: Per-sample calculation then average (like original notebook)\n",
        "def dice_coefficient(pred, target, threshold=0.6, smooth=1e-6):\n",
        "    \"\"\"Calculate Dice per sample, then average across batch.\"\"\"\n",
        "    pred = torch.sigmoid(pred)\n",
        "    pred = (pred > threshold).float()\n",
        "    # Sum over spatial dims (H,W) per sample - keep batch dim!\n",
        "    intersection = (pred * target).sum(dim=(1, 2, 3))\n",
        "    union = pred.sum(dim=(1, 2, 3)) + target.sum(dim=(1, 2, 3))\n",
        "    dice = (2 * intersection + smooth) / (union + smooth)\n",
        "    return dice.mean()\n",
        "\n",
        "def iou_score(pred, target, threshold=0.5, smooth=1e-6):\n",
        "    \"\"\"Calculate IoU per sample, then average across batch.\"\"\"\n",
        "    pred = torch.sigmoid(pred)\n",
        "    pred = (pred > threshold).float()\n",
        "    intersection = (pred * target).sum(dim=(1, 2, 3))\n",
        "    union = pred.sum(dim=(1, 2, 3)) + target.sum(dim=(1, 2, 3)) - intersection\n",
        "    iou = (intersection + smooth) / (union + smooth)\n",
        "    return iou.mean()\n",
        "\n",
        "def precision_score(pred, target, threshold=0.5, smooth=1e-6):\n",
        "    \"\"\"Calculate Precision per sample, then average across batch.\"\"\"\n",
        "    pred = torch.sigmoid(pred)\n",
        "    pred = (pred > threshold).float()\n",
        "    tp = (pred * target).sum(dim=(1, 2, 3))  # True Positives\n",
        "    fp = (pred * (1 - target)).sum(dim=(1, 2, 3))  # False Positives\n",
        "    precision = (tp + smooth) / (tp + fp + smooth)\n",
        "    return precision.mean()\n",
        "\n",
        "def recall_score(pred, target, threshold=0.5, smooth=1e-6):\n",
        "    \"\"\"Calculate Recall (Sensitivity) per sample, then average across batch.\"\"\"\n",
        "    pred = torch.sigmoid(pred)\n",
        "    pred = (pred > threshold).float()\n",
        "    tp = (pred * target).sum(dim=(1, 2, 3))  # True Positives\n",
        "    fn = ((1 - pred) * target).sum(dim=(1, 2, 3))  # False Negatives\n",
        "    recall = (tp + smooth) / (tp + fn + smooth)\n",
        "    return recall.mean()\n",
        "\n",
        "def f1_score(pred, target, threshold=0.5, smooth=1e-6):\n",
        "    \"\"\"Calculate F1 Score (harmonic mean of precision and recall).\"\"\"\n",
        "    pred = torch.sigmoid(pred)\n",
        "    pred = (pred > threshold).float()\n",
        "    tp = (pred * target).sum(dim=(1, 2, 3))\n",
        "    fp = (pred * (1 - target)).sum(dim=(1, 2, 3))\n",
        "    fn = ((1 - pred) * target).sum(dim=(1, 2, 3))\n",
        "    precision = (tp + smooth) / (tp + fp + smooth)\n",
        "    recall = (tp + smooth) / (tp + fn + smooth)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall + smooth)\n",
        "    return f1.mean()\n",
        "\n",
        "def accuracy_score(pred, target, threshold=0.5):\n",
        "    \"\"\"Calculate Accuracy per sample, then average across batch.\"\"\"\n",
        "    pred = torch.sigmoid(pred)\n",
        "    pred = (pred > threshold).float()\n",
        "    correct = (pred == target).float()\n",
        "    accuracy = correct.sum(dim=(1, 2, 3)) / target.numel() * target.size(0)  # Normalize by spatial size\n",
        "    return accuracy.mean()\n",
        "\n",
        "print(\"‚úÖ Loss functions and augmentations defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Dataset & Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset class defined\n"
          ]
        }
      ],
      "source": [
        "class PneumothoraxDataset(Dataset):\n",
        "    \"\"\"Dataset with MAX POOLING for mask downsampling to preserve small regions.\"\"\"\n",
        "    \n",
        "    def __init__(self, df, images_dir, masks_dir, transform=None, \n",
        "                 patch_size=256, is_training=True, use_patches=False):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.images_dir = images_dir\n",
        "        self.masks_dir = masks_dir\n",
        "        self.transform = transform\n",
        "        self.patch_size = patch_size\n",
        "        self.is_training = is_training\n",
        "        self.use_patches = use_patches\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def _max_pool_downsample_mask(self, mask, target_size):\n",
        "        \"\"\"\n",
        "        KEY IMPROVEMENT: Use max pooling to preserve small pneumothorax regions.\n",
        "        Standard cv2.resize() can lose small regions during 1024‚Üí256 downsampling.\n",
        "        Max pooling ensures any positive pixel in each 4x4 block is preserved.\n",
        "        \"\"\"\n",
        "        h, w = mask.shape\n",
        "        if h == target_size and w == target_size:\n",
        "            return mask\n",
        "        \n",
        "        ratio = h // target_size\n",
        "        if ratio > 1 and h % target_size == 0 and w % target_size == 0:\n",
        "            # Perfect divisibility - use efficient reshape + max\n",
        "            mask_reshaped = mask.reshape(target_size, ratio, target_size, ratio)\n",
        "            mask_downsampled = mask_reshaped.max(axis=(1, 3))\n",
        "            return mask_downsampled\n",
        "        else:\n",
        "            # Fallback to nearest neighbor (still better than bilinear for masks)\n",
        "            return cv2.resize(mask, (target_size, target_size), interpolation=cv2.INTER_NEAREST)\n",
        "    \n",
        "    def _random_crop(self, image, mask):\n",
        "        h, w = image.shape[:2]\n",
        "        max_y, max_x = max(0, h - self.patch_size), max(0, w - self.patch_size)\n",
        "        if max_y == 0 and max_x == 0:\n",
        "            image = cv2.resize(image, (self.patch_size, self.patch_size))\n",
        "            mask = self._max_pool_downsample_mask(mask, self.patch_size)\n",
        "            return image, mask\n",
        "        y, x = np.random.randint(0, max_y + 1), np.random.randint(0, max_x + 1)\n",
        "        return image[y:y+self.patch_size, x:x+self.patch_size], mask[y:y+self.patch_size, x:x+self.patch_size]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        filename = self.df.iloc[idx]['new_filename']\n",
        "        image = cv2.imread(os.path.join(self.images_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
        "        mask = cv2.imread(os.path.join(self.masks_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "        \n",
        "        if self.use_patches and self.is_training:\n",
        "            image, mask = self._random_crop(image, mask)\n",
        "        else:\n",
        "            # CHANGED: Use max pooling for masks to preserve small pneumothorax regions!\n",
        "            image = cv2.resize(image, (self.patch_size, self.patch_size))\n",
        "            mask = self._max_pool_downsample_mask(mask, self.patch_size)\n",
        "        \n",
        "        mask = (mask > 127).astype(np.float32)\n",
        "        mask = np.expand_dims(mask, axis=-1)\n",
        "        \n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=image, mask=mask)\n",
        "            image, mask = transformed['image'], transformed['mask']\n",
        "        \n",
        "        mask = mask.permute(2, 0, 1) if mask.dim() == 3 else mask.unsqueeze(0)\n",
        "        return image, mask\n",
        "\n",
        "print(\"‚úÖ Dataset class defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Total samples in CSV: 10675\n",
            "üìÇ Images dir: siim-acr-pneumothorax/png_images (exists: True)\n",
            "üìÇ Masks dir: siim-acr-pneumothorax/png_masks (exists: True)\n",
            "\n",
            "üîç Validating all images and computing stratification (accelerated)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d48bad4d1494318b5859b4b54efe86c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Checking images:   0%|          | 0/10675 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "libpng error: IDAT: CRC error\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Data Summary:\n",
            "   Original samples: 10675\n",
            "   Valid samples: 10674\n",
            "   ‚ö†Ô∏è Filtered out: 1 corrupted/invalid images\n",
            "   Examples: ['5548_train_0_.png']\n",
            "\n",
            "üìä Class distribution (valid images only):\n",
            "   With pneumothorax: 2379 (22.3%)\n",
            "   Without: 8295 (77.7%)\n"
          ]
        }
      ],
      "source": [
        "# Load CSV and filter corrupted images (with GPU acceleration using torch and torchvision)\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import torch\n",
        "import torchvision.io\n",
        "\n",
        "train_csv_path = os.path.join(config.DATA_PATH, config.TRAIN_CSV)\n",
        "df_raw = pd.read_csv(train_csv_path)\n",
        "images_dir = os.path.join(config.DATA_PATH, config.IMAGES_DIR)\n",
        "masks_dir = os.path.join(config.DATA_PATH, config.MASKS_DIR)\n",
        "\n",
        "print(f\"üìÅ Total samples in CSV: {len(df_raw)}\")\n",
        "print(f\"üìÇ Images dir: {images_dir} (exists: {os.path.exists(images_dir)})\")\n",
        "print(f\"üìÇ Masks dir: {masks_dir} (exists: {os.path.exists(masks_dir)})\")\n",
        "\n",
        "def validate_sample(idx):\n",
        "    filename = df_raw.iloc[idx]['new_filename']\n",
        "    image_path = os.path.join(images_dir, filename)\n",
        "    mask_path = os.path.join(masks_dir, filename)\n",
        "    try:\n",
        "        # Use torchvision.io.read_image for GPU tensor if available\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        img = torchvision.io.read_image(image_path).to(device)\n",
        "        # Convert to grayscale if needed (our png is grayscale but we might get as C,H,W)\n",
        "        if img.shape[0] > 1:\n",
        "            img = img.mean(dim=0, keepdim=True)\n",
        "        h, w = img.shape[1:]\n",
        "        img_mean = img.float().mean().item()\n",
        "        mask = torchvision.io.read_image(mask_path).to(device)\n",
        "        if mask.shape[0] > 1:\n",
        "            mask = mask.mean(dim=0, keepdim=True)\n",
        "        mask_max = mask.max().item() if mask is not None else 0\n",
        "        if img is not None and h > 100 and w > 100 and img_mean > 5:\n",
        "            # Valid image\n",
        "            return idx, 1 if mask is not None and mask_max > 0 else 0, None\n",
        "        else:\n",
        "            return None, None, filename\n",
        "    except Exception as e:\n",
        "        return None, None, filename\n",
        "\n",
        "# GPU-accelerated \"validation\" of each image/mask sample using threads\n",
        "print(\"\\nüîç Validating all images and computing stratification (accelerated)...\")\n",
        "valid_indices = []\n",
        "has_pneumothorax = []\n",
        "corrupted_files = []\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=16) as executor:\n",
        "    futures = [executor.submit(validate_sample, idx) for idx in range(len(df_raw))]\n",
        "    for f in tqdm(futures, desc=\"Checking images\"):\n",
        "        try:\n",
        "            idx, pneumo, corrupt = f.result()\n",
        "            if idx is not None:\n",
        "                valid_indices.append(idx)\n",
        "                has_pneumothorax.append(pneumo)\n",
        "            elif corrupt:\n",
        "                corrupted_files.append(corrupt)\n",
        "        except Exception:\n",
        "            # This should not happen, but just in case\n",
        "            continue\n",
        "\n",
        "# Create filtered dataframe\n",
        "df = df_raw.iloc[valid_indices].reset_index(drop=True)\n",
        "has_pneumothorax = np.array(has_pneumothorax)\n",
        "\n",
        "print(f\"\\nüìä Data Summary:\")\n",
        "print(f\"   Original samples: {len(df_raw)}\")\n",
        "print(f\"   Valid samples: {len(df)}\")\n",
        "if corrupted_files:\n",
        "    print(f\"   ‚ö†Ô∏è Filtered out: {len(corrupted_files)} corrupted/invalid images\")\n",
        "    print(f\"   Examples: {corrupted_files[:5]}\")\n",
        "\n",
        "print(f\"\\nüìä Class distribution (valid images only):\")\n",
        "print(f\"   With pneumothorax: {has_pneumothorax.sum()} ({100*has_pneumothorax.mean():.1f}%)\")\n",
        "print(f\"   Without: {len(has_pneumothorax) - has_pneumothorax.sum()} ({100*(1-has_pneumothorax.mean()):.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚≠ê Class rebalancing enabled: Positive cases oversampled for ~50/50 balance\n",
            "\n",
            "üìÇ Data split: Train=8539, Val=2135\n",
            "   Train batches: 533, Val batches: 134\n"
          ]
        }
      ],
      "source": [
        "# Create train/val split and dataloaders\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "\n",
        "train_df, val_df = train_test_split(df, test_size=config.VAL_SPLIT, stratify=has_pneumothorax, random_state=config.SEED)\n",
        "\n",
        "train_dataset = PneumothoraxDataset(train_df, images_dir, masks_dir, get_training_augmentation(config.PATCH_SIZE), \n",
        "                                     config.PATCH_SIZE, is_training=True, use_patches=config.USE_PATCHES)\n",
        "val_dataset = PneumothoraxDataset(val_df, images_dir, masks_dir, get_validation_augmentation(), \n",
        "                                   config.PATCH_SIZE, is_training=False, use_patches=False)\n",
        "\n",
        "# ‚≠ê KAGGLE TRICK #1: Class Rebalancing (ENABLED)\n",
        "# Oversample positive cases for better learning on rare pneumothorax cases\n",
        "# With gradient clipping + lower LR, this should be stable\n",
        "USE_CLASS_REBALANCING = True\n",
        "\n",
        "if USE_CLASS_REBALANCING:\n",
        "    train_has_pneumothorax = has_pneumothorax[train_df.index.values]\n",
        "    class_counts = np.bincount(train_has_pneumothorax.astype(int))\n",
        "    class_weights = 1.0 / class_counts\n",
        "    sample_weights = class_weights[train_has_pneumothorax.astype(int)]\n",
        "    \n",
        "    sampler = WeightedRandomSampler(\n",
        "        weights=sample_weights,\n",
        "        num_samples=len(sample_weights),\n",
        "        replacement=True\n",
        "    )\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, sampler=sampler,\n",
        "                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n",
        "    print(f\"   ‚≠ê Class rebalancing enabled: Positive cases oversampled for ~50/50 balance\")\n",
        "else:\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True,\n",
        "                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n",
        "    print(f\"   üìä Using standard shuffling (class rebalancing disabled for stability)\")\n",
        "\n",
        "val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, \n",
        "                        num_workers=config.NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "print(f\"\\nüìÇ Data split: Train={len(train_df)}, Val={len(val_df)}\")\n",
        "print(f\"   Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Model & Training Setup üß†\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üß† Model: UNet++ with Attention (resnet34)\n",
            "   Parameters: 26,281,332\n",
            "   Loss: Focal + Œª*Dice (Œª=0.5, Œ±=0.25, Œ≥=2.0)\n",
            "   Dropout: 0.1 (decoder blocks)\n",
            "   Optimizer: AdamW (lr=8e-05, wd=1e-05)\n",
            "   Scheduler: ReduceLROnPlateau (factor=0.5, patience=5, min_lr=1e-7)\n"
          ]
        }
      ],
      "source": [
        "# Create UNet++ model (better than vanilla U-Net with nested skip connections)\n",
        "# CHANGED: UnetPlusPlus has better feature fusion via nested/dense skip pathways\n",
        "model = smp.UnetPlusPlus(\n",
        "    encoder_name=config.ENCODER, \n",
        "    encoder_weights=config.ENCODER_WEIGHTS,\n",
        "    in_channels=3, \n",
        "    classes=1, \n",
        "    activation=None, \n",
        "    decoder_attention_type=config.ATTENTION_TYPE,\n",
        "    decoder_dropout=config.DECODER_DROPOUT if config.USE_DROPOUT else 0.0  # ‚≠ê SpatialDropout2D in decoder blocks\n",
        ")\n",
        "model = model.to(config.DEVICE)\n",
        "\n",
        "# Training setup - Loss function selection\n",
        "# Standard formulation: L = BCE/Focal + Œª * Dice (BCE/Focal at full weight, Dice weighted by Œª)\n",
        "if config.LOSS_TYPE == 'focal_dice':\n",
        "    criterion = DiceFocalLoss(\n",
        "        dice_weight=config.DICE_WEIGHT,  # Œª parameter\n",
        "        focal_alpha=config.FOCAL_ALPHA,\n",
        "        focal_gamma=config.FOCAL_GAMMA\n",
        "    )\n",
        "    loss_info = f\"Focal + Œª*Dice (Œª={config.DICE_WEIGHT}, Œ±={config.FOCAL_ALPHA}, Œ≥={config.FOCAL_GAMMA})\"\n",
        "else:\n",
        "    criterion = DiceBCELoss(dice_weight=config.DICE_WEIGHT)  # Œª parameter\n",
        "    loss_info = f\"BCE + Œª*Dice (Œª={config.DICE_WEIGHT}, standard formulation)\"\n",
        "\n",
        "# CHANGED: AdamW with weight decay for better generalization\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)\n",
        "# Keep ReduceLROnPlateau - adapts to validation performance\n",
        "# FIXED: Increased patience for stability (was 3, now 5)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, min_lr=1e-7)\n",
        "scaler = GradScaler(enabled=config.MIXED_PRECISION)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"\\nüß† Model: UNet++ with Attention ({config.ENCODER})\")\n",
        "print(f\"   Parameters: {total_params:,}\")\n",
        "print(f\"   Loss: {loss_info}\")\n",
        "print(f\"   Dropout: {config.DECODER_DROPOUT if config.USE_DROPOUT else 'Disabled'} (decoder blocks)\")\n",
        "print(f\"   Optimizer: AdamW (lr={config.LEARNING_RATE}, wd={config.WEIGHT_DECAY})\")\n",
        "print(f\"   Scheduler: ReduceLROnPlateau (factor=0.5, patience=5, min_lr=1e-7)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Training Loop üöÄ\n",
        "\n",
        "**Choose ONE of the following cells based on your config:**\n",
        "- Cell 6A: Single Split Training (when `USE_KFOLD = False`)\n",
        "- Cell 6B: K-Fold Cross-Validation (when `USE_KFOLD = True`)\n",
        "\n",
        "### 6A. Single Split Training (Default - Faster)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üöÄ STARTING SINGLE-SPLIT TRAINING\n",
            "============================================================\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3dd1d3e34cb4c2cbf0b0b7ddd982109",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1/30:   0%|          | 0/533 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ‚ö†Ô∏è RUN THIS CELL ONLY IF USE_KFOLD = False\n",
        "if config.USE_KFOLD:\n",
        "    print(\"‚ö†Ô∏è USE_KFOLD is True - Skip this cell and run Section 6B instead!\")\n",
        "    best_dice = 0.0  # Placeholder\n",
        "    best_iou = 0.0\n",
        "    history = {}\n",
        "    best_model_path = \"\"\n",
        "else:\n",
        "    # Training history\n",
        "    history = {\n",
        "        'train_loss': [], 'train_dice': [], 'train_f1': [],\n",
        "        'val_loss': [], 'val_dice': [], 'val_iou': [], 'val_f1': []\n",
        "    }\n",
        "    best_dice = 0.0\n",
        "    best_iou = 0.0\n",
        "    patience_counter = 0\n",
        "    best_model_path = None  # Will be set when saving\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üöÄ STARTING SINGLE-SPLIT TRAINING\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    for epoch in range(config.EPOCHS):\n",
        "        # === TRAINING ===\n",
        "        model.train()\n",
        "        train_loss, train_dice, train_f1 = 0.0, 0.0, 0.0\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{config.EPOCHS}\")\n",
        "        for batch_idx, (images, masks) in pbar:\n",
        "            images, masks = images.to(config.DEVICE), masks.to(config.DEVICE)\n",
        "            \n",
        "            with autocast(enabled=config.MIXED_PRECISION):\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, masks) / config.GRADIENT_ACCUMULATION\n",
        "            \n",
        "            scaler.scale(loss).backward()\n",
        "            \n",
        "            if (batch_idx + 1) % config.GRADIENT_ACCUMULATION == 0:\n",
        "                # ‚≠ê Gradient clipping for stability (especially with class rebalancing)\n",
        "                scaler.unscale_(optimizer)  # Unscale gradients before clipping\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                \n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "            \n",
        "            train_loss += loss.item() * config.GRADIENT_ACCUMULATION * images.size(0)\n",
        "            train_dice += dice_coefficient(outputs, masks).item() * images.size(0)\n",
        "            train_f1 += f1_score(outputs, masks).item() * images.size(0)\n",
        "            pbar.set_postfix({'loss': f'{loss.item()*config.GRADIENT_ACCUMULATION:.4f}'})\n",
        "        \n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_dice /= len(train_loader.dataset)\n",
        "        train_f1 /= len(train_loader.dataset)\n",
        "        \n",
        "        # === VALIDATION ===\n",
        "        model.eval()\n",
        "        val_loss, val_dice, val_iou, val_f1 = 0.0, 0.0, 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            for images, masks in val_loader:\n",
        "                images, masks = images.to(config.DEVICE), masks.to(config.DEVICE)\n",
        "                with autocast(enabled=config.MIXED_PRECISION):\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, masks)\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                val_dice += dice_coefficient(outputs, masks).item() * images.size(0)\n",
        "                val_iou += iou_score(outputs, masks).item() * images.size(0)\n",
        "                val_f1 += f1_score(outputs, masks).item() * images.size(0)\n",
        "        \n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_dice /= len(val_loader.dataset)\n",
        "        val_iou /= len(val_loader.dataset)\n",
        "        val_f1 /= len(val_loader.dataset)\n",
        "        \n",
        "        scheduler.step(val_dice)  # FIXED: ReduceLROnPlateau needs the metric value\n",
        "        # scheduler.step()\n",
        "        \n",
        "        # Save history\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_dice'].append(train_dice)\n",
        "        history['train_f1'].append(train_f1)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_dice'].append(val_dice)\n",
        "        history['val_iou'].append(val_iou)\n",
        "        history['val_f1'].append(val_f1)\n",
        "        \n",
        "        print(f\"\\nüìä Epoch {epoch+1}: Train Loss={train_loss:.4f}, Train Dice={train_dice:.4f}, Train F1={train_f1:.4f}\")\n",
        "        print(f\"   Val Loss={val_loss:.4f}, Val Dice={val_dice:.4f}, Val IoU={val_iou:.4f}, Val F1={val_f1:.4f}\")\n",
        "        \n",
        "        # Save best model with metrics in filename\n",
        "        if val_dice > best_dice:\n",
        "            best_dice = val_dice\n",
        "            best_iou = val_iou\n",
        "            patience_counter = 0\n",
        "            # Create descriptive filename: pneumo_dice{D}_iou{I}_ep{E}.pth\n",
        "            model_name = f\"pneumo_dice{val_dice:.4f}_iou{val_iou:.4f}_ep{epoch+1}.pth\"\n",
        "            best_model_path = os.path.join(config.OUTPUT_DIR, model_name)\n",
        "            torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), \n",
        "                        'val_dice': val_dice, 'val_iou': val_iou, 'history': history,\n",
        "                        'encoder': config.ENCODER, 'patch_size': config.PATCH_SIZE}, best_model_path)\n",
        "            print(f\"   ‚úÖ New best model saved: {model_name}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"   ‚è≥ No improvement ({patience_counter}/{config.PATIENCE})\")\n",
        "        \n",
        "        if patience_counter >= config.PATIENCE:\n",
        "            print(f\"\\nüõë Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"üéâ TRAINING COMPLETE! Best Dice: {best_dice:.4f}\")\n",
        "    print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6B. K-Fold Cross-Validation (Optional - More Robust)\n",
        "\n",
        "‚ö†Ô∏è **Run this cell ONLY if `USE_KFOLD = True` in config**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‚ö†Ô∏è RUN THIS CELL ONLY IF USE_KFOLD = True\n",
        "if not config.USE_KFOLD:\n",
        "    print(\"‚ö†Ô∏è USE_KFOLD is False - Skip this cell, you already ran 6A!\")\n",
        "    fold_results = []\n",
        "else:\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"üöÄ STARTING {config.N_FOLDS}-FOLD CROSS-VALIDATION\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    kfold = StratifiedKFold(n_splits=config.N_FOLDS, shuffle=True, random_state=config.SEED)\n",
        "    fold_results = []\n",
        "    \n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(df, has_pneumothorax)):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"üìÅ FOLD {fold+1}/{config.N_FOLDS}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        # Split data\n",
        "        fold_train_df = df.iloc[train_idx]\n",
        "        fold_val_df = df.iloc[val_idx]\n",
        "        print(f\"   Train: {len(fold_train_df)}, Val: {len(fold_val_df)}\")\n",
        "        \n",
        "        # Create datasets\n",
        "        fold_train_dataset = PneumothoraxDataset(\n",
        "            fold_train_df, images_dir, masks_dir, \n",
        "            get_training_augmentation(config.PATCH_SIZE),\n",
        "            config.PATCH_SIZE, is_training=True, use_patches=config.USE_PATCHES\n",
        "        )\n",
        "        fold_val_dataset = PneumothoraxDataset(\n",
        "            fold_val_df, images_dir, masks_dir,\n",
        "            get_validation_augmentation(),\n",
        "            config.PATCH_SIZE, is_training=False, use_patches=False\n",
        "        )\n",
        "        \n",
        "        fold_train_loader = DataLoader(fold_train_dataset, batch_size=config.BATCH_SIZE,\n",
        "                                       shuffle=True, num_workers=config.NUM_WORKERS, \n",
        "                                       pin_memory=True, drop_last=True)\n",
        "        fold_val_loader = DataLoader(fold_val_dataset, batch_size=config.BATCH_SIZE,\n",
        "                                     shuffle=False, num_workers=config.NUM_WORKERS, pin_memory=True)\n",
        "        \n",
        "        # Fresh model for each fold - UNet++ with nested skip connections\n",
        "        fold_model = smp.UnetPlusPlus(\n",
        "            encoder_name=config.ENCODER, \n",
        "            encoder_weights=config.ENCODER_WEIGHTS,\n",
        "            in_channels=3, \n",
        "            classes=1, \n",
        "            activation=None, \n",
        "            decoder_attention_type=config.ATTENTION_TYPE,\n",
        "            decoder_dropout=config.DECODER_DROPOUT if config.USE_DROPOUT else 0.0  # SpatialDropout2D in decoder blocks\n",
        "        ).to(config.DEVICE)\n",
        "        \n",
        "        # CHANGED: AdamW + ReduceLROnPlateau\n",
        "        fold_optimizer = torch.optim.AdamW(fold_model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)\n",
        "        fold_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(fold_optimizer, mode='max', factor=0.5, patience=3)\n",
        "        fold_scaler = GradScaler(enabled=config.MIXED_PRECISION)\n",
        "        \n",
        "        fold_history = {'train_loss': [], 'train_dice': [], 'val_loss': [], 'val_dice': [], 'val_iou': []}\n",
        "        fold_best_dice = 0.0\n",
        "        fold_best_iou = 0.0\n",
        "        fold_patience = 0\n",
        "        fold_model_path = None  # Will be set when saving\n",
        "        \n",
        "        for epoch in range(config.EPOCHS):\n",
        "            # Training\n",
        "            fold_model.train()\n",
        "            train_loss, train_dice = 0.0, 0.0\n",
        "            fold_optimizer.zero_grad()\n",
        "            \n",
        "            pbar = tqdm(enumerate(fold_train_loader), total=len(fold_train_loader), \n",
        "                       desc=f\"Fold {fold+1} Epoch {epoch+1}\", leave=False)\n",
        "            for batch_idx, (images, masks) in pbar:\n",
        "                images, masks = images.to(config.DEVICE), masks.to(config.DEVICE)\n",
        "                with autocast(enabled=config.MIXED_PRECISION):\n",
        "                    outputs = fold_model(images)\n",
        "                    loss = criterion(outputs, masks) / config.GRADIENT_ACCUMULATION\n",
        "                fold_scaler.scale(loss).backward()\n",
        "                if (batch_idx + 1) % config.GRADIENT_ACCUMULATION == 0:\n",
        "                    fold_scaler.step(fold_optimizer)\n",
        "                    fold_scaler.update()\n",
        "                    fold_optimizer.zero_grad()\n",
        "                train_loss += loss.item() * config.GRADIENT_ACCUMULATION * images.size(0)\n",
        "                train_dice += dice_coefficient(outputs, masks).item() * images.size(0)\n",
        "            \n",
        "            train_loss /= len(fold_train_loader.dataset)\n",
        "            train_dice /= len(fold_train_loader.dataset)\n",
        "            \n",
        "            # Validation\n",
        "            fold_model.eval()\n",
        "            val_loss, val_dice, val_iou = 0.0, 0.0, 0.0\n",
        "            with torch.no_grad():\n",
        "                for images, masks in fold_val_loader:\n",
        "                    images, masks = images.to(config.DEVICE), masks.to(config.DEVICE)\n",
        "                    with autocast(enabled=config.MIXED_PRECISION):\n",
        "                        outputs = fold_model(images)\n",
        "                        loss = criterion(outputs, masks)\n",
        "                    val_loss += loss.item() * images.size(0)\n",
        "                    val_dice += dice_coefficient(outputs, masks).item() * images.size(0)\n",
        "                    val_iou += iou_score(outputs, masks).item() * images.size(0)\n",
        "            \n",
        "            val_loss /= len(fold_val_loader.dataset)\n",
        "            val_dice /= len(fold_val_loader.dataset)\n",
        "            val_iou /= len(fold_val_loader.dataset)\n",
        "            \n",
        "            fold_scheduler.step(val_dice)  # FIXED: ReduceLROnPlateau needs the metric value\n",
        "            # fold_scheduler.step()\n",
        "            fold_history['train_loss'].append(train_loss)\n",
        "            fold_history['train_dice'].append(train_dice)\n",
        "            fold_history['val_loss'].append(val_loss)\n",
        "            fold_history['val_dice'].append(val_dice)\n",
        "            fold_history['val_iou'].append(val_iou)\n",
        "            \n",
        "            # Save best model with metrics in filename\n",
        "            if val_dice > fold_best_dice:\n",
        "                fold_best_dice = val_dice\n",
        "                fold_best_iou = val_iou\n",
        "                fold_patience = 0\n",
        "                # Create descriptive filename: pneumo_fold{F}_dice{D}_iou{I}_ep{E}.pth\n",
        "                model_name = f\"pneumo_fold{fold}_dice{val_dice:.4f}_iou{val_iou:.4f}_ep{epoch+1}.pth\"\n",
        "                fold_model_path = os.path.join(config.OUTPUT_DIR, model_name)\n",
        "                torch.save({'fold': fold, 'epoch': epoch, 'model_state_dict': fold_model.state_dict(),\n",
        "                           'val_dice': val_dice, 'val_iou': val_iou, 'history': fold_history,\n",
        "                           'encoder': config.ENCODER, 'patch_size': config.PATCH_SIZE}, fold_model_path)\n",
        "            else:\n",
        "                fold_patience += 1\n",
        "            \n",
        "            if fold_patience >= config.PATIENCE:\n",
        "                print(f\"   Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "        \n",
        "        fold_results.append({'fold': fold, 'best_dice': fold_best_dice, 'best_iou': fold_best_iou, \n",
        "                             'history': fold_history, 'model_path': fold_model_path})\n",
        "        print(f\"   ‚úÖ Fold {fold+1} Best Dice: {fold_best_dice:.4f}, IoU: {fold_best_iou:.4f}\")\n",
        "    \n",
        "    # Summary\n",
        "    fold_dices = [r['best_dice'] for r in fold_results]\n",
        "    fold_ious = [r['best_iou'] for r in fold_results]\n",
        "    best_fold_idx = np.argmax(fold_dices)\n",
        "    best_dice = np.mean(fold_dices)\n",
        "    best_iou = np.mean(fold_ious)\n",
        "    history = fold_results[best_fold_idx]['history']  # Use best fold's history for plotting\n",
        "    best_model_path = fold_results[best_fold_idx]['model_path']  # Best fold's model path\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üìä K-FOLD CROSS-VALIDATION RESULTS\")\n",
        "    print(\"=\" * 60)\n",
        "    for i, (d, iou) in enumerate(zip(fold_dices, fold_ious)):\n",
        "        print(f\"   Fold {i+1}: Dice = {d:.4f}, IoU = {iou:.4f}\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"   Mean Dice: {np.mean(fold_dices):.4f} ¬± {np.std(fold_dices):.4f}\")\n",
        "    print(f\"   Mean IoU:  {np.mean(fold_ious):.4f} ¬± {np.std(fold_ious):.4f}\")\n",
        "    print(f\"   Best Fold: {best_fold_idx+1} (Dice: {max(fold_dices):.4f})\")\n",
        "    print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7. Kaggle Tricks: Optimal Threshold & TTA üéØ\n",
        "\n",
        "‚≠ê **Post-Training Enhancements** to boost performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‚≠ê KAGGLE TRICK #2: Find Optimal Threshold\n",
        "# Don't just use 0.5! Find the threshold that maximizes Dice on validation set\n",
        "\n",
        "def find_optimal_threshold(model, val_loader, device, search_range=(0.3, 0.7, 0.05)):\n",
        "    \"\"\"\n",
        "    Find threshold that maximizes Dice coefficient on validation set.\n",
        "    \n",
        "    ‚ö†Ô∏è MEMORY-EFFICIENT VERSION: Processes predictions in batches instead of storing all.\n",
        "    This prevents OOM crashes on systems with limited RAM.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    best_threshold = 0.5\n",
        "    best_dice = 0.0\n",
        "    \n",
        "    print(f\"üéØ Searching for optimal threshold in range {search_range[0]:.2f}-{search_range[1]:.2f}...\")\n",
        "    print(\"   (Memory-efficient: processing in batches)\\n\")\n",
        "    thresholds = np.arange(search_range[0], search_range[1], search_range[2])\n",
        "    \n",
        "    # Evaluate each threshold by iterating through validation set\n",
        "    for threshold in thresholds:\n",
        "        total_dice = 0.0\n",
        "        num_batches = 0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for images, masks in val_loader:\n",
        "                images = images.to(device)\n",
        "                masks = masks.to(device)\n",
        "                \n",
        "                # Get predictions\n",
        "                outputs = torch.sigmoid(model(images))\n",
        "                pred_binary = (outputs > threshold).float()\n",
        "                \n",
        "                # Calculate Dice for this batch\n",
        "                batch_dice = dice_coefficient(pred_binary, masks, threshold=0.5).item()\n",
        "                total_dice += batch_dice\n",
        "                num_batches += 1\n",
        "        \n",
        "        # Average Dice across all batches\n",
        "        dice = total_dice / num_batches if num_batches > 0 else 0.0\n",
        "        \n",
        "        if dice > best_dice:\n",
        "            best_dice = dice\n",
        "            best_threshold = threshold\n",
        "        print(f\"   Threshold {threshold:.2f}: Dice = {dice:.4f}\")\n",
        "    \n",
        "    # Calculate baseline Dice at 0.5 for comparison\n",
        "    baseline_dice = 0.0\n",
        "    num_batches = 0\n",
        "    with torch.no_grad():\n",
        "        for images, masks in val_loader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "            outputs = torch.sigmoid(model(images))\n",
        "            pred_binary = (outputs > 0.5).float()\n",
        "            batch_dice = dice_coefficient(pred_binary, masks, threshold=0.5).item()\n",
        "            baseline_dice += batch_dice\n",
        "            num_batches += 1\n",
        "    baseline_dice = baseline_dice / num_batches if num_batches > 0 else 0.0\n",
        "    \n",
        "    print(f\"\\n‚úÖ Optimal threshold: {best_threshold:.2f}\")\n",
        "    print(f\"   Dice improvement: {best_dice:.4f} (vs {baseline_dice:.4f} at 0.5)\")\n",
        "    return best_threshold, best_dice\n",
        "    \n",
        "# Find optimal threshold if training completed\n",
        "if 'best_model_path' in locals() and best_model_path and os.path.exists(best_model_path):\n",
        "    optimal_threshold, optimal_dice = find_optimal_threshold(model, val_loader, config.DEVICE)\n",
        "else:\n",
        "    optimal_threshold = 0.5\n",
        "    print(\"‚ö†Ô∏è No trained model found, using default threshold=0.5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‚≠ê KAGGLE TRICK #3: Test-Time Augmentation (TTA)\n",
        "# Apply horizontal flip during inference and average predictions\n",
        "\n",
        "def predict_with_tta(model, image, device, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Apply Test-Time Augmentation for more robust predictions.\n",
        "    \n",
        "    For chest X-rays, we only flip horizontally (not vertically).\n",
        "    Pneumothorax can occur on either side, so horizontal flip is valid.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Original prediction\n",
        "        pred1 = torch.sigmoid(model(image.unsqueeze(0).to(device)))\n",
        "        \n",
        "        # Horizontal flip prediction\n",
        "        image_hflip = torch.flip(image, [2])  # flip width dimension\n",
        "        pred2 = torch.sigmoid(model(image_hflip.unsqueeze(0).to(device)))\n",
        "        pred2 = torch.flip(pred2, [3])  # flip prediction back\n",
        "        \n",
        "        # Average predictions\n",
        "        pred_avg = (pred1 + pred2) / 2\n",
        "    \n",
        "    # Apply threshold\n",
        "    pred_binary = (pred_avg > threshold).float()\n",
        "    return pred_avg.squeeze().cpu().numpy(), pred_binary.squeeze().cpu().numpy()\n",
        "\n",
        "print(\"‚úÖ TTA function defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 8. Training Curves üìà\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if history and len(history.get('train_loss', [])) > 0:\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "    axes[0].plot(epochs, history['train_loss'], 'b-', label='Train', linewidth=2)\n",
        "    axes[0].plot(epochs, history['val_loss'], 'r-', label='Val', linewidth=2)\n",
        "    axes[0].set_xlabel('Epoch'); axes[0].set_ylabel('Loss'); axes[0].set_title('Loss Curves')\n",
        "    axes[0].legend(); axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[1].plot(epochs, history['train_dice'], 'b-', label='Train Dice', linewidth=2)\n",
        "    axes[1].plot(epochs, history['val_dice'], 'r-', label='Val Dice', linewidth=2)\n",
        "    axes[1].axhline(y=0.85, color='green', linestyle='--', label='Target (0.85)', alpha=0.7)\n",
        "    axes[1].set_xlabel('Epoch'); axes[1].set_ylabel('Dice Score'); axes[1].set_title('Dice Score')\n",
        "    axes[1].legend(); axes[1].grid(True, alpha=0.3); axes[1].set_ylim(0, 1)\n",
        "\n",
        "    axes[2].plot(epochs, history['val_iou'], 'g-', label='Val IoU', linewidth=2)\n",
        "    axes[2].set_xlabel('Epoch'); axes[2].set_ylabel('IoU'); axes[2].set_title('Validation IoU')\n",
        "    axes[2].legend(); axes[2].grid(True, alpha=0.3); axes[2].set_ylim(0, 1)\n",
        "\n",
        "    title = f'Training Results (Best Dice: {best_dice:.4f})' if not config.USE_KFOLD else f'Best Fold Results (Dice: {max([r[\"best_dice\"] for r in fold_results]):.4f})'\n",
        "    plt.suptitle(title, fontsize=16, y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(config.OUTPUT_DIR, 'training_curves.png'), dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No training history to plot\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 8.5. Comprehensive Evaluation on Dev/Test Sets üìä\n",
        "\n",
        "Evaluate the trained model with **all metrics** (Dice, IoU, F1, Precision, Recall, Accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def comprehensive_evaluate(model, data_loader, device, split_name=\"Evaluation\", threshold=0.5):\n",
        "    \"\"\"\n",
        "    Comprehensive evaluation with all metrics: Dice, IoU, F1, Precision, Recall, Accuracy.\n",
        "    \n",
        "    Args:\n",
        "        model: Trained model\n",
        "        data_loader: DataLoader for the dataset to evaluate\n",
        "        device: Device to run evaluation on\n",
        "        split_name: Name of the split (e.g., \"Validation\", \"Test\")\n",
        "        threshold: Threshold for binary predictions\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with all metrics\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_metrics = {\n",
        "        'loss': 0.0,\n",
        "        'dice': 0.0,\n",
        "        'iou': 0.0,\n",
        "        'f1': 0.0,\n",
        "        'precision': 0.0,\n",
        "        'recall': 0.0,\n",
        "        'accuracy': 0.0\n",
        "    }\n",
        "    \n",
        "    total_samples = 0\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üìä {split_name.upper()} EVALUATION\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(data_loader, desc=f\"Evaluating {split_name}\")\n",
        "        for images, masks in pbar:\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            \n",
        "            with autocast(enabled=config.MIXED_PRECISION):\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, masks)\n",
        "            \n",
        "            batch_size = images.size(0)\n",
        "            total_samples += batch_size\n",
        "            \n",
        "            # Calculate all metrics\n",
        "            all_metrics['loss'] += loss.item() * batch_size\n",
        "            all_metrics['dice'] += dice_coefficient(outputs, masks, threshold=threshold).item() * batch_size\n",
        "            all_metrics['iou'] += iou_score(outputs, masks, threshold=threshold).item() * batch_size\n",
        "            all_metrics['f1'] += f1_score(outputs, masks, threshold=threshold).item() * batch_size\n",
        "            all_metrics['precision'] += precision_score(outputs, masks, threshold=threshold).item() * batch_size\n",
        "            all_metrics['recall'] += recall_score(outputs, masks, threshold=threshold).item() * batch_size\n",
        "            all_metrics['accuracy'] += accuracy_score(outputs, masks, threshold=threshold).item() * batch_size\n",
        "    \n",
        "    # Average over all samples\n",
        "    for key in all_metrics:\n",
        "        all_metrics[key] /= total_samples\n",
        "    \n",
        "    # Print results\n",
        "    print(f\"\\nüìà Results (threshold={threshold}):\")\n",
        "    print(f\"   Loss:      {all_metrics['loss']:.4f}\")\n",
        "    print(f\"   Dice:      {all_metrics['dice']:.4f}\")\n",
        "    print(f\"   IoU:       {all_metrics['iou']:.4f}\")\n",
        "    print(f\"   F1 Score:  {all_metrics['f1']:.4f}\")\n",
        "    print(f\"   Precision: {all_metrics['precision']:.4f}\")\n",
        "    print(f\"   Recall:    {all_metrics['recall']:.4f}\")\n",
        "    print(f\"   Accuracy:  {all_metrics['accuracy']:.4f}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    return all_metrics\n",
        "\n",
        "# Evaluate on validation set\n",
        "if 'best_model_path' in locals() and best_model_path and os.path.exists(best_model_path):\n",
        "    print(\"üîç Loading best model for evaluation...\")\n",
        "    checkpoint = torch.load(best_model_path, map_location=config.DEVICE)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    \n",
        "    # Use optimal threshold if available, otherwise use 0.5\n",
        "    eval_threshold = optimal_threshold if 'optimal_threshold' in locals() else 0.5\n",
        "    \n",
        "    val_metrics = comprehensive_evaluate(model, val_loader, config.DEVICE, \n",
        "                                         split_name=\"Validation\", threshold=eval_threshold)\n",
        "    \n",
        "    # If test set exists, evaluate on it too\n",
        "    if 'test_loader' in locals():\n",
        "        test_metrics = comprehensive_evaluate(model, test_loader, config.DEVICE,\n",
        "                                             split_name=\"Test\", threshold=eval_threshold)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No trained model found. Run training cells first!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 9. Visualize Predictions with TTA üéØ\n",
        "\n",
        "Using **optimal threshold** and **Test-Time Augmentation** for best results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model\n",
        "if best_model_path and os.path.exists(best_model_path):\n",
        "    checkpoint = torch.load(best_model_path, map_location=config.DEVICE)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "    print(f\"‚úÖ Loaded best model: {os.path.basename(best_model_path)}\")\n",
        "    print(f\"   Dice: {checkpoint['val_dice']:.4f}, IoU: {checkpoint.get('val_iou', 'N/A')}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No model checkpoint found - skipping predictions\")\n",
        "\n",
        "# Visualize predictions with TTA and optimal threshold\n",
        "# CORRECT: Use same normalization as training (0.5, 0.5, 0.5) for grayscale\n",
        "GRAYSCALE_MEAN = np.array([0.5, 0.5, 0.5])\n",
        "GRAYSCALE_STD = np.array([0.5, 0.5, 0.5])\n",
        "\n",
        "# Use optimal threshold if found, otherwise default to 0.5\n",
        "threshold = optimal_threshold if 'optimal_threshold' in locals() else 0.5\n",
        "print(f\"\\nüéØ Using threshold: {threshold:.2f} for predictions\")\n",
        "\n",
        "fig, axes = plt.subplots(5, 4, figsize=(16, 18))\n",
        "indices = np.random.choice(len(val_dataset), 5, replace=False)\n",
        "\n",
        "for i, idx in enumerate(indices):\n",
        "    image, mask = val_dataset[idx]\n",
        "    \n",
        "    # ‚≠ê Use TTA for more robust predictions\n",
        "    if 'predict_with_tta' in globals():\n",
        "        pred_prob, pred_binary = predict_with_tta(model, image, config.DEVICE, threshold=threshold)\n",
        "    else:\n",
        "        # Fallback to standard prediction\n",
        "        with torch.no_grad():\n",
        "            pred = model(image.unsqueeze(0).to(config.DEVICE))\n",
        "            pred_prob = torch.sigmoid(pred).squeeze().cpu().numpy()\n",
        "            pred_binary = (pred_prob > threshold).astype(float)\n",
        "    \n",
        "    img = image.permute(1, 2, 0).numpy()\n",
        "    # Denormalize using same stats as training\n",
        "    img = img * GRAYSCALE_STD + GRAYSCALE_MEAN\n",
        "    img = np.clip(img, 0, 1)\n",
        "    mask_np = mask.squeeze().numpy()\n",
        "    \n",
        "    intersection = (pred_binary * mask_np).sum()\n",
        "    sample_dice = 2 * intersection / (pred_binary.sum() + mask_np.sum() + 1e-6)\n",
        "    \n",
        "    axes[i, 0].imshow(img); axes[i, 0].set_title('Input'); axes[i, 0].axis('off')\n",
        "    axes[i, 1].imshow(mask_np, cmap='gray'); axes[i, 1].set_title('Ground Truth'); axes[i, 1].axis('off')\n",
        "    axes[i, 2].imshow(pred_prob, cmap='jet', vmin=0, vmax=1); axes[i, 2].set_title(f'Prob (T={threshold:.2f})'); axes[i, 2].axis('off')\n",
        "    axes[i, 3].imshow(pred_binary, cmap='gray'); axes[i, 3].set_title(f'Pred+TTA (D={sample_dice:.3f})'); axes[i, 3].axis('off')\n",
        "\n",
        "plt.suptitle('Model Predictions with TTA & Optimal Threshold', fontsize=16, y=1.01)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(config.OUTPUT_DIR, 'predictions_tta.png'), dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 10. Save Results üíæ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Build summary based on training mode\n",
        "if config.USE_KFOLD and len(fold_results) > 0:\n",
        "    fold_dices = [r['best_dice'] for r in fold_results]\n",
        "    summary = {\n",
        "        'mode': 'kfold',\n",
        "        'n_folds': config.N_FOLDS,\n",
        "        'mean_dice': float(np.mean(fold_dices)),\n",
        "        'std_dice': float(np.std(fold_dices)),\n",
        "        'fold_dices': [float(d) for d in fold_dices],\n",
        "        'best_fold': int(np.argmax(fold_dices)),\n",
        "        'config': {'encoder': config.ENCODER, 'patch_size': config.PATCH_SIZE,\n",
        "                   'batch_size': config.BATCH_SIZE, 'learning_rate': config.LEARNING_RATE}\n",
        "    }\n",
        "    final_dice = np.mean(fold_dices)\n",
        "    final_iou = np.mean([max(r['history']['val_iou']) for r in fold_results])\n",
        "else:\n",
        "    summary = {\n",
        "        'mode': 'single_split',\n",
        "        'best_dice': float(best_dice),\n",
        "        'best_iou': float(max(history['val_iou'])) if history else 0,\n",
        "        'epochs_trained': len(history['train_loss']) if history else 0,\n",
        "        'config': {'encoder': config.ENCODER, 'patch_size': config.PATCH_SIZE, \n",
        "                   'batch_size': config.BATCH_SIZE, 'learning_rate': config.LEARNING_RATE},\n",
        "        'history': {k: [float(x) for x in v] for k, v in history.items()} if history else {}\n",
        "    }\n",
        "    final_dice = best_dice\n",
        "    final_iou = max(history['val_iou']) if history and 'val_iou' in history else 0\n",
        "\n",
        "with open(os.path.join(config.OUTPUT_DIR, 'training_summary.json'), 'w') as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "print(f\"\\n‚úÖ Results saved to {config.OUTPUT_DIR}/\")\n",
        "if best_model_path:\n",
        "    print(f\"   - {os.path.basename(best_model_path)}\")\n",
        "print(f\"   - training_curves.png\")\n",
        "print(f\"   - predictions.png\")\n",
        "print(f\"   - training_summary.json\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üìä FINAL SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "if config.USE_KFOLD and len(fold_results) > 0:\n",
        "    print(f\"üîÑ Mode: {config.N_FOLDS}-Fold Cross-Validation\")\n",
        "    print(f\"üèÜ Mean Dice: {np.mean(fold_dices):.4f} ¬± {np.std(fold_dices):.4f}\")\n",
        "else:\n",
        "    print(f\"üîÑ Mode: Single Split\")\n",
        "    print(f\"üèÜ Best Dice: {final_dice:.4f}\")\n",
        "    print(f\"üèÜ Best IoU:  {final_iou:.4f}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if final_dice >= 0.85:\n",
        "    print(\"\\nüéâ TARGET ACHIEVED! Dice ‚â• 0.85\")\n",
        "else:\n",
        "    print(f\"\\nüìà Dice {final_dice:.4f} - Consider more epochs or tuning\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "global",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
